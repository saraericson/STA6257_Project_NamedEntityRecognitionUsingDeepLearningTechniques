<!DOCTYPE html>
<html lang="en"><head>
<script src="NER_Slides_files/libs/clipboard/clipboard.min.js"></script>
<script src="NER_Slides_files/libs/quarto-html/tabby.min.js"></script>
<script src="NER_Slides_files/libs/quarto-html/popper.min.js"></script>
<script src="NER_Slides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="NER_Slides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="NER_Slides_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="NER_Slides_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.2.269">

  <meta name="author" content="Sara Ericson, Andrew Campbell, Jorge Sanchez">
  <title>NER using RNNs and Transformer Models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="NER_Slides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="NER_Slides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="NER_Slides_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="NER_Slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="NER_Slides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="NER_Slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="NER_Slides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">NER using RNNs and Transformer Models</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Sara Ericson, Andrew Campbell, Jorge Sanchez 
</div>
</div>
</div>

</section>
<section id="ner-what-is-it" class="slide level2">
<h2>NER, what is it?</h2>
<div>
<ul>
<li>Named Entity Recognition (NER) is a task in Natural Language Processing (NLP) that involves identifying and extracting named entities from unstructured text.
<ul>
<li>This means identifying and classifying entities into categories that are predefined (person, place, etc.)</li>
</ul></li>
<li>Biomedical NER is the task of text mining to specifically biomedical texts to determine entity types.</li>
<li>Similarly, medical NER tasks mine specifically medical texts for entity types.</li>
</ul>
</div>
</section>
<section id="purpose-of-this-review" class="slide level2">
<h2>Purpose of this review</h2>
<div>
<ul>
<li><p>We are testing different deep learning techniques and their effectiveness of NER on data containing information on Medical Conditions, Medicine Names, and Pathogens.</p></li>
<li><p>The methods we chose are:</p>
<ul>
<li>Recurrent Neural Network (RNN): a method of deep learning that is used for sequential data and time-series data.</li>
<li>Transformer Model: a model designed for sequence-to-sequence tasks, such as machine translation, and is known for its ability to process input sequences in parallel rather than sequentially.</li>
</ul></li>
</ul>
</div>
</section>
<section id="limitations" class="slide level2">
<h2>Limitations</h2>
<div>
<ul>
<li>Current NER techniques have major limitations being that the standard language models are unidirectional, operating in a single direction, and thus limit the choice of architecture that can be used for pre-training.</li>
<li>While the deep learning techniques we have chosen are not perfect, they do directly address this major limitation and we will show their effectiveness moving forward.</li>
</ul>
</div>
</section>
<section id="limitations-1" class="slide level2">
<h2>Limitations</h2>
<div>
<ul>
<li><p>Limitations of our chosen techniques:</p>
<ul>
<li><p>Transformer model: The size of the training data can be a limitation here. If there is not enough training data it can make the model less effective.</p></li>
<li><p>RNN: RNN‚Äôs are prone to over fitting which is especially true when there is a small dataset</p></li>
</ul></li>
</ul>
</div>
</section>
<section id="what-is-transformer-model" class="slide level2">
<h2>What is Transformer Model?</h2>
<div>
<ul>
<li><p>The Transformer model is a neural network architecture designed for sequence-to-sequence tasks such as machine translation.</p></li>
<li><p>The model‚Äôs key innovation is the self-attention mechanism, which allows it to weight the importance of different words in the input sequence.</p></li>
<li><p>Self-attention enables the model to capture long-range dependencies and handle complex language structures effectively.</p></li>
</ul>
</div>
</section>
<section id="transformer-architecture" class="slide level2">
<h2>Transformer Architecture</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><img data-src="images/transformer%20Architecture.png"></p>
</div><div class="column" style="width:40%;">
<ul>
<li><p>Encoder</p></li>
<li><p>Decoder</p></li>
<li><p>Positional Encoding</p></li>
<li><p>Multi-Head Attention</p></li>
</ul>
</div>
</div>
</section>
<section id="transformer-methods" class="slide level2">
<h2>Transformer Methods</h2>
<div>
<ul>
<li class="fragment"><p>Scaled Dot-Product Attention formula<br>
<br>
<span class="math inline">\(\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V\)</span><br>
</p></li>
<li class="fragment"><p>The Single (Masked) Self- or Cross-Attention Head Formula <span class="math inline">\(\begin{align*}\text{Attention}(Q, K, V) &amp;= \text{softmax}\left(\frac{QK^\top + \text{Mask}}{\sqrt{d_k}}\right)V \\\end{align*}\)</span></p></li>
</ul>
</div>
</section>
<section id="transformer---how-to-do-it" class="slide level2">
<h2>Transformer - How to do it?</h2>
<div class="incrememtal">
<ol type="1">
<li><p>Annotated Dataset for Training</p>
<ul>
<li>Labelstud.io , Prodi.gy</li>
</ul></li>
<li><p>Pre-process the dataset</p>
<ul>
<li>Tokenization - NLTK</li>
</ul></li>
<li><p>Fine-tune a pre-trained Tranformer Model</p>
<ul>
<li>Huggingface - BERT</li>
</ul></li>
<li><p>Train</p></li>
<li><p>Evaluate</p>
<ul>
<li>Metrics: Precision,recall and F1 score.</li>
</ul></li>
</ol>
</div>
</section>
<section id="transformer-limitations" class="slide level2">
<h2>Transformer Limitations</h2>
<div>
<ul>
<li class="fragment"><p>Standard language models are unidirectional, restricting pre-training architecture options and limiting context awareness.</p></li>
<li class="fragment"><p>Transformers have high computational complexity due to numerous parameters, requiring significant resources and specialized hardware for deep models and long sequences.</p></li>
</ul>
</div>
</section>
<section id="dataset" class="slide level2">
<h2>Dataset</h2>
<div>
<p>We will use the dataset called corona2 from Kaggle to identify Natural Entity Recognition to identify Medical Condition, Medicine names and Pathogens. Similarly to the dataset used in the dataset was manually tagged for training.</p>
<ul>
<li class="fragment"><p>Labels:</p>
<ul>
<li class="fragment">Medical condition names (example: influenza, headache, malaria)</li>
<li class="fragment">Medicine names (example : aspirin, penicillin, ribavirin, methotrexate)</li>
<li class="fragment">Pathogens ( example: Corona Virus, Zika Virus, cynobacteria, E. Coli)</li>
</ul></li>
</ul>
</div>
</section>
<section id="dataset-definition" class="slide level2">
<h2>Dataset Definition</h2>
<div>
<table>
<colgroup>
<col style="width: 26%">
<col style="width: 26%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Column Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Text</td>
<td>string</td>
<td>Sentence including the labels</td>
</tr>
<tr class="even">
<td>Starts</td>
<td>integer</td>
<td>Position on where the label starts</td>
</tr>
<tr class="odd">
<td>Ends</td>
<td>integer</td>
<td>Position on where the label ends</td>
</tr>
<tr class="even">
<td>Labels</td>
<td>string</td>
<td>The label( Medical Condition, Medicine or Pathogen)</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="dataset-sample" class="slide level2">
<h2>Dataset Sample</h2>
<div>
<p>Text: Buprenorphine has been shown experimentally (1982‚Äì1995) to be effective against severe, refractory depression.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/annotated1.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="images/annotated2.png"></p>
</div>
</div>
</div>
</section>
<section id="dataset-visualization---labels" class="slide level2">
<h2>Dataset Visualization - Labels</h2>
<div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/frequency_labels-01.png"></p>
</figure>
</div>
</div>
</section>
<section id="data-visualization---position" class="slide level2">
<h2>Data Visualization - Position</h2>
<div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/start_end_Positions-01.png"></p>
</figure>
</div>
</div>
</section>
<section id="what-is-a-recurrent-neural-network-rnn-starting-with-a-neural-network" class="slide level2">
<h2>What is a Recurrent Neural Network (RNN) starting with a Neural Network</h2>
<div>
<ul>
<li class="fragment">A basic neural network has an input layer, a hidden layer or layers, and an output layer</li>
<li class="fragment">Between the layers are weights and biases that are used in the calculation of the output</li>
<li class="fragment">The network is optimized using back propagation and a gradient descent algorithm</li>
<li class="fragment">Back propagation is used to find the gradient of a parameter</li>
<li class="fragment">A gradient descent algorithm is used to find values that minimize a loss function (such as error)</li>
</ul>
</div>
</section>
<section id="what-is-a-recurrent-neural-network-rnn-starting-with-a-neural-network-1" class="slide level2">
<h2>What is a Recurrent Neural Network (RNN) starting with a Neural Network</h2>
<div>
<p>Example of a Loss function (Mean Squared Error):<br>
<span class="math inline">\(\text{L(ùúΩ)} = (1/N) * ‚àë(y_i - y_i^*)^2\)</span><br>
Gradient Descent Algorithm:<br>
<span class="math inline">\(\text{ùúΩ}_j =ùúΩ_j - ùõº (‚àÇJ(ùúΩ) / ‚àÇùúΩ_j)\)</span><br>
N : number of vector entries with yi in output vector</p>
<p>yi : predicted value</p>
<p>yi* : actual value</p>
<p>ùõº : learning rate</p>
<p>ùúΩj : input</p>
</div>
</section>
<section id="what-makes-rnn-different" class="slide level2">
<h2>What makes RNN different?</h2>
<div>
<ul>
<li>A recurrent neural network is similar to a basic neural network but with the addition of a feedback loop</li>
<li>In these networks activation functions (∆í) are used to determine whether a neuron in the network is turned on or off</li>
<li>The data in feedback loop is included with the input of subsequent data</li>
<li>This allows for past data to influence the calculations of future outputs which is why RNNs are great for sequential data such as text</li>
</ul>
</div>
</section>
<section id="what-makes-rnn-different-1" class="slide level2">
<h2>What makes RNN different?</h2>
<div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Screen%20Shot%202023-04-26%20at%206.14.17%20PM-01.png" width="462"></p>
</figure>
</div>
</div>
</section>
<section id="limitations-of-rnn" class="slide level2">
<h2>Limitations of RNN</h2>
<div>
<ul>
<li>One of the main problems RNNs face is an exploding or vanishing gradient</li>
<li>This can occur when a large amount of data is used</li>
<li>The weight in the feedback loop (W_h) becomes multiplied on itself over and over which will results in an extremely large or extremely small value</li>
</ul>
</div>
</section>
<section id="limitiations" class="slide level2">
<h2>Limitiations</h2>
<div>
<ul>
<li>For example if the weight is 3 and there are 10 data points the weight will end up being 3 to the power of ten (59049). When applied to larger data sets this number can become much larger. This number is then used in the gradient descent calculation resulting in an optimization step that is way too big which in turn results in overfitting.</li>
<li>For smaller weights such as 0.5 with 10 data points the weight will be 0.000977. This will result in an optimization step that is way too small.</li>
</ul>
</div>
</section>
<section id="solution-to-exploding-and-vanishing-gradient" class="slide level2">
<h2>Solution to exploding and vanishing gradient</h2>
<div>
<ul>
<li>A common solution to exploding and vanishing gradient is a Long Short-Term Memory (LSTM) cell</li>
<li>These cells are located in the feedback loop and contain three gates within the cell
<ol type="1">
<li><p>Input gate: determines which information is stored in the cell</p></li>
<li><p>Forget gate: determines which information will be discarded</p></li>
<li><p>Output gate: provides the activation for the final output</p></li>
</ol></li>
</ul>
</div>
</section>
<section id="solution-to-exploding-and-vanishing-gradient-1" class="slide level2">
<h2>Solution to exploding and vanishing gradient</h2>
<div>
<ul>
<li><p>These gates use a sigmoid function which outputs a value between zero and one</p></li>
<li><p>0 blocks all information and 1 allows all information through</p>
<p>Sigmoid: <span class="math inline">\(\text{f(x)} = {1/(1+e^{-x})}\)</span></p>
<p>General gate equation: <span class="math inline">\(\text{g}_i = ùùà(w[h_{i-1}, x_i] + b)\)</span></p>
<p>x : input, ùùà : sigmoid function, w : weight, h : information of i-th iteration, b : bias</p></li>
</ul>
</div>
</section>
<section id="rnn-continued" class="slide level2">
<h2>RNN Continued</h2>
<div>
<ul>
<li>LSTMs maintain a cell state as a result of the calculations from the equations below along with the sigmoid and the general gate equation</li>
<li>This state is what provides the ‚Äúmemory‚Äù which makes it useful in named entity recognition</li>
<li>Using LSTM cells in recurrent neural networks allows the network to be applied to large datasets which is very beneficial in the context of named entity recognition</li>
</ul>
</div>
</section>
<section id="equations-for-lstms" class="slide level2">
<h2>Equations for LSTMs</h2>
<div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Screen%20Shot%202023-04-26%20at%209.12.04%20PM.png"></p>
</figure>
</div>
</div>
</section>
<section id="libraries-needed-for-data-manipulation" class="slide level2">
<h2>Libraries needed for data manipulation</h2>
<div>
<ul>
<li><p><strong>nbclient</strong> : Executes Jupyter notebooks programmatically</p></li>
<li><p><strong>requests</strong> : Sends HTTP requests and interacts with RESTful APIs in Python</p></li>
<li><p><strong>pandas</strong> : Manipulates and analyzes tabular data using DataFrame and Series</p></li>
<li><p><strong>nbformat</strong> : Reads, writes, and manipulates Jupyter Notebook files</p></li>
<li><p><strong>plotly.express</strong> : Creates interactive data visualizations with a simple interface</p></li>
</ul>
</div>
</section>
<section id="parse-data-into-dictionary-to-manipulate-data." class="slide level2">
<h2>Parse data into dictionary to manipulate data.</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a>training_data <span class="op">=</span> []</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="cf">for</span> example <span class="kw">in</span> data[<span class="st">'examples'</span>]:</span>
<span id="cb1-3"><a href="#cb1-3"></a>  temp_dict <span class="op">=</span> {}</span>
<span id="cb1-4"><a href="#cb1-4"></a>  temp_dict[<span class="st">'text'</span>] <span class="op">=</span> example[<span class="st">'content'</span>]</span>
<span id="cb1-5"><a href="#cb1-5"></a>  temp_dict[<span class="st">'entities'</span>] <span class="op">=</span> []</span>
<span id="cb1-6"><a href="#cb1-6"></a>  <span class="cf">for</span> annotation <span class="kw">in</span> example[<span class="st">'annotations'</span>]:</span>
<span id="cb1-7"><a href="#cb1-7"></a>    start <span class="op">=</span> annotation[<span class="st">'start'</span>]</span>
<span id="cb1-8"><a href="#cb1-8"></a>    end <span class="op">=</span> annotation[<span class="st">'end'</span>]</span>
<span id="cb1-9"><a href="#cb1-9"></a>    label <span class="op">=</span> annotation[<span class="st">'tag_name'</span>].upper()</span>
<span id="cb1-10"><a href="#cb1-10"></a>    temp_dict[<span class="st">'entities'</span>].append((start, end, label))</span>
<span id="cb1-11"><a href="#cb1-11"></a>  training_data.append(temp_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="convert-data-from-dictionary-to-dataframe" class="slide level2">
<h2>Convert data from Dictionary to Dataframe</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Initialing empty lists to store the data for the DataFrame</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>texts <span class="op">=</span> []</span>
<span id="cb2-3"><a href="#cb2-3"></a>starts <span class="op">=</span> []</span>
<span id="cb2-4"><a href="#cb2-4"></a>ends <span class="op">=</span> []</span>
<span id="cb2-5"><a href="#cb2-5"></a>labels <span class="op">=</span> []</span>
<span id="cb2-6"><a href="#cb2-6"></a></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co"># Iterate through the training_data to extract individual entity annotations</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="cf">for</span> example <span class="kw">in</span> training_data:</span>
<span id="cb2-9"><a href="#cb2-9"></a>    text <span class="op">=</span> example[<span class="st">'text'</span>]</span>
<span id="cb2-10"><a href="#cb2-10"></a>    <span class="cf">for</span> entity <span class="kw">in</span> example[<span class="st">'entities'</span>]:</span>
<span id="cb2-11"><a href="#cb2-11"></a>        start, end, label <span class="op">=</span> entity</span>
<span id="cb2-12"><a href="#cb2-12"></a>        <span class="co"># Append data to the lists</span></span>
<span id="cb2-13"><a href="#cb2-13"></a>        texts.append(text)</span>
<span id="cb2-14"><a href="#cb2-14"></a>        starts.append(start)</span>
<span id="cb2-15"><a href="#cb2-15"></a>        ends.append(end)</span>
<span id="cb2-16"><a href="#cb2-16"></a>        labels.append(label)</span>
<span id="cb2-17"><a href="#cb2-17"></a></span>
<span id="cb2-18"><a href="#cb2-18"></a><span class="co"># Create a DataFrame from the lists</span></span>
<span id="cb2-19"><a href="#cb2-19"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">'text'</span>: texts, <span class="st">'start'</span>: starts, <span class="st">'end'</span>: ends, <span class="st">'label'</span>: labels})</span>
<span id="cb2-20"><a href="#cb2-20"></a>df.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="first-five-entries-in-dataframe" class="slide level2">
<h2>First five entries in dataframe</h2>
<div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Screen%20Shot%202023-04-26%20at%209.22.16%20PM-01.png" width="503"></p>
</figure>
</div>
</div>
</section>
<section id="rnn-libraries" class="slide level2">
<h2>RNN Libraries</h2>
<p>Load required libraries for the RNN.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> LSTM, Dense, Dropout, TimeDistributed, Bidirectional</span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="im">from</span> tensorflow.keras.preprocessing.sequence <span class="im">import</span> pad_sequences</span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="im">from</span> tensorflow.keras.utils <span class="im">import</span> to_categorical</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rnn-code" class="slide level2">
<h2>RNN Code</h2>
<ul>
<li><p>Using the dataframe created before a vocabulary of words and labels was created and then converted into indices</p></li>
<li><p>The sequences are then padded to a maximum length and then converted to one-hot encoded vectors</p></li>
<li><p>A one-hot encoded vector is a binary vector in which the label is encoded as 1 and everything else that is not the label is encoded as 0</p></li>
<li><p>This is necessary to train the model with tensorflow</p></li>
</ul>
</section>
<section id="rnn-code-1" class="slide level2">
<h2>RNN Code</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>words <span class="op">=</span> <span class="bu">set</span>(df[<span class="st">'text'</span>].values)</span>
<span id="cb4-2"><a href="#cb4-2"></a>word2idx <span class="op">=</span> {w: i <span class="op">+</span> <span class="dv">2</span> <span class="cf">for</span> i, w <span class="kw">in</span> <span class="bu">enumerate</span>(words)}</span>
<span id="cb4-3"><a href="#cb4-3"></a>word2idx[<span class="st">'PAD'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>word2idx[<span class="st">'UNK'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-5"><a href="#cb4-5"></a></span>
<span id="cb4-6"><a href="#cb4-6"></a>tags <span class="op">=</span> <span class="bu">set</span>(df[<span class="st">'label'</span>].values)</span>
<span id="cb4-7"><a href="#cb4-7"></a>tag2idx <span class="op">=</span> {t: i <span class="op">+</span> <span class="dv">1</span> <span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(tags)}</span>
<span id="cb4-8"><a href="#cb4-8"></a>tag2idx[<span class="st">'PAD'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-9"><a href="#cb4-9"></a></span>
<span id="cb4-10"><a href="#cb4-10"></a>X <span class="op">=</span> [[word2idx.get(w, <span class="dv">1</span>) <span class="cf">for</span> w <span class="kw">in</span> sentence.split()] <span class="cf">for</span> sentence <span class="kw">in</span> df[<span class="st">'text'</span>].values]</span>
<span id="cb4-11"><a href="#cb4-11"></a>y <span class="op">=</span> [[tag2idx[t] <span class="cf">for</span> t <span class="kw">in</span> sentence.split()] <span class="cf">for</span> sentence <span class="kw">in</span> df[<span class="st">'label'</span>].values]</span>
<span id="cb4-12"><a href="#cb4-12"></a></span>
<span id="cb4-13"><a href="#cb4-13"></a>maxlen <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(x) <span class="cf">for</span> x <span class="kw">in</span> X)</span>
<span id="cb4-14"><a href="#cb4-14"></a>X <span class="op">=</span> pad_sequences(X, padding<span class="op">=</span><span class="st">'post'</span>, maxlen<span class="op">=</span>maxlen)</span>
<span id="cb4-15"><a href="#cb4-15"></a>y <span class="op">=</span> pad_sequences(y, padding<span class="op">=</span><span class="st">'post'</span>, maxlen<span class="op">=</span>maxlen)</span>
<span id="cb4-16"><a href="#cb4-16"></a>y <span class="op">=</span> to_categorical(y, num_classes<span class="op">=</span><span class="bu">len</span>(tag2idx))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="after-the-data-is-manipulated-the-rnn-model-is-created-and-compiled-with-the-use-of-tensorflow" class="slide level2">
<h2>After the data is manipulated the RNN model is created and compiled with the use of tensorflow</h2>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb5-2"><a href="#cb5-2"></a>    tf.keras.layers.Embedding(<span class="bu">len</span>(word2idx), <span class="dv">128</span>),</span>
<span id="cb5-3"><a href="#cb5-3"></a>    tf.keras.layers.LSTM(<span class="dv">128</span>, return_sequences<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb5-4"><a href="#cb5-4"></a>    tf.keras.layers.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb5-5"><a href="#cb5-5"></a>    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(<span class="bu">len</span>(tag2idx), activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb5-6"><a href="#cb5-6"></a>])</span>
<span id="cb5-7"><a href="#cb5-7"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="lastly-the-model-is-fitted-and-the-accuracy-is-calculated" class="slide level2">
<h2>Lastly the model is fitted and the accuracy is calculated</h2>
<div>
<p>The RNN model‚Äôs accuracy is 0.9967</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>model.fit(X, y, batch_size<span class="op">=</span><span class="dv">32</span>, epochs<span class="op">=</span><span class="dv">10</span>, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Screen%20Shot%202023-04-26%20at%208.56.26%20PM.png" width="413"></p>
</figure>
</div>
</div>
</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<div>
<ul>
<li class="fragment">NER is a key NLP task that involves identifying named entities in a text.</li>
<li class="fragment">Deep learning techniques have become more mainstream in the NER field due to their major advantages.</li>
<li class="fragment">The techniques we have chose, RNN and Transformer Model, have shown this to be true for various situations.</li>
</ul>
</div>
</section>
<section id="conclusion-1" class="slide level2">
<h2>Conclusion</h2>
<div>
<ul>
<li class="fragment"><p>The accuracy of our models were:</p>
<ul>
<li class="fragment">Transformer Model: 0.9375</li>
<li class="fragment">RNN: 0.9967</li>
</ul></li>
<li class="fragment"><p>This shoes that when doing NER for our chosen dataset, RNN was more effective after training, but that both are over 90% accurate given the data that we have used</p></li>
</ul>
</div>
<div class="footer footer-default">

</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="NER_Slides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="NER_Slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="NER_Slides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="NER_Slides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="NER_Slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="NER_Slides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="NER_Slides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="NER_Slides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="NER_Slides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="NER_Slides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>